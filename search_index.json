[
["index.html", "EigenGWAS theory and application Chapter 1 EigenGWAS basis 1.1 Genetic relatedness matrix \\(\\mathbf{G}\\) 1.2 EigenGWAS linear model 1.3 Connection to SVD 1.4 Classic mechanic intepretation", " EigenGWAS theory and application Guo-Bo Chen [chen.guobo@foxmail.com] 2018-11-29 Chapter 1 EigenGWAS basis This project is dedicated to EigenGWAS, a linear model analysis approach for eigenvectors on genomic data, which can be represented as \\(\\mathbf{X}\\) the \\(n \\times m\\) genotype matrix. Without loss of generality, \\(x_{jl}\\) is a biallic code for the \\(i^{th}\\) individual at the \\(l^{th}\\) locus. The data matrix \\(\\mathbf{X}\\) can be generated from genotyping chips, NGS, or GBS. 1.1 Genetic relatedness matrix \\(\\mathbf{G}\\) We can construct the \\(n\\times\\) genetic relatedness matrix as \\(\\mathbf{X}\\) the \\(n\\times m\\) genotype matrix. We can construct the \\(n\\times\\) genetic relatedness matrix as \\[\\mathbf{G}=\\tilde{\\mathbf{X}}\\tilde{\\mathbf{X}}^T\\] in which \\(\\tilde{\\mathbf{X}}\\) is the scaled form of \\(\\mathbf{X}\\) However, upon the mating type of the species, \\(\\mathbf{G}\\) should be constructly differently. For a random mating population, \\(x_l\\) is scaled as \\(\\tilde{x}_l=\\frac{x_l-2p_l}{\\sqrt{2p_lq_l}}\\), whereas for inbred population, \\(\\tilde{x}_l=\\frac{x_l-2p_l}{\\sqrt{4p_lq_l}}\\). \\(q_l\\) equals \\(1-p_l\\). So for a pair of individuals \\(i\\) and \\(j\\), \\[\\begin{equation} G_{ij}=\\frac{1}{\\tilde{m}}\\sum_l^{\\tilde{m}}\\frac{(x_{il}-2p_l)(x_{jl}-2p_l)}{2(1+F)p_lq_l} \\tag{1.1} \\end{equation}\\] in which \\(\\tilde{m}\\) is the number of genotyped loci at both individal \\(i\\) and \\(j\\), and \\(F\\) the inbreeding coefficient takes value of 0 for random mating population and 1 for inbred population. 1.1.1 Statistical properties of \\(\\mathbf{G}\\) Given \\(\\mathbf{G}\\), we can define two population parameters, \\(n_e\\), the effective population size, and \\(m_e\\), the effective number of markers. Let \\(\\mathbf{G}_o\\) denote the off diagonal elements of \\(\\mathbf{G}\\), then we have \\[\\begin{equation} n_e=\\frac{-1}{mean(\\mathbf{G}_o)} \\tag{1.2} \\end{equation}\\] \\(n_e\\) reflects true relatedness between any pair of samples; \\[\\begin{equation} m_e=\\frac{1}{Var(\\mathbf{G}_o)} \\tag{1.3} \\end{equation}\\] The ratio between \\(\\frac{m_e}{m}\\) reflects the average linkage disequilibrium between the any pair of markers, and alternatively \\(m_e\\) can be expressed as \\[\\begin{equation} m_e=\\frac{\\sum_{l_1=1}^m\\sum_{l_2=1}^m\\rho_{l_1l_2}^2}{m^2}=\\bar{\\rho}^2 \\tag{1.4} \\end{equation}\\] in which \\(\\rho_{l_1l_2}\\) is Pearson’s correlation between a pair of SNPs. It is an important parameter to describe the evolutionary process of a population of study. 1.2 EigenGWAS linear model Given eigenanalysis of \\(\\mathbf{X}\\), we have \\(\\mathbf{E}\\) and \\(\\mathbf{\\Lambda}\\), in which \\(\\mathbf{\\Lambda}\\) is an \\(n \\times n\\) diagonal matrix for eigenvalues and \\(\\mathbf{E}\\) is an \\(n \\times n\\) matrix for the eigenvectors. \\(\\mathbf{E}_k\\) is the eigenvector associated with the \\(k^{th}\\) largest eigenvalue. Regressing \\(\\mathbf{E}_k\\) against each marker, we have the model below \\[\\begin{equation} \\mathbf{E}_k=a+\\beta_j\\mathbf{x}_i+e \\tag{1.5} \\end{equation}\\] It consequently generates \\(m\\) estimates of \\(\\beta\\), \\(\\sigma_j\\), and their corresponding \\(p\\) values. Given the \\(m\\) \\(p\\) values, the conventional Manhattan plot can be made. In particular, the one-degree-of-freedom \\(\\chi^2_1\\) has approximation as \\[\\begin{equation} 4\\frac{\\color{red}{n_1}\\color{blue}{n_2}}{n}\\frac{(\\color{red}{p_{1,l}}-\\color{blue}{p_{2,l}})^2}{2\\bar{p}_l\\bar{q}_l}=4n\\omega_1 \\omega_2 F_{st}^N=nF_{st}^W \\tag{1.6} \\end{equation}\\] in which \\(\\color{red}{n_1}\\) and \\(\\color{blue}{n_2}\\) are the numbers of samples at the left and right side of “0” on the eigenvector, see the figure below. \\(\\color{red}{p_{1,l}}\\) and \\(\\color{blue}{p_{2,l}}\\) are frequencies of the reference allele in two subgroups, respectively. \\(\\bar{p_l}\\) is the allele frequency of the reference allele. \\(F_{st}^N=\\frac{(\\color{red}{p_{1,l}}-\\color{blue}{p_{2,l}})^2}{2\\bar{p}_l\\bar{q}_l}\\) and \\(F_{st}^W=2\\frac{\\sum_{g=1}^2\\omega_g(p_{g,l}-{\\bar p_l})^2}{\\bar{p}_l\\bar{q}_l}\\). set.seed(2018) layout(matrix(1:4, 2, 2)) freq = runif(1000, 0.1, 0.9) X = matrix(0, 100, length(freq)) for (i in 1:length(freq)) { X[, i] = rbinom(nrow(X), 2, freq[i]) } print(dim(X)) ## [1] 100 1000 plot(freq, colMeans(X)/2, xlab = &quot;Simulated frequency&quot;, ylab = &quot;Estimated frequency&quot;, bty = &quot;n&quot;, pch = 16, cex = 0.5) abline(a = 0, b = 1, col = &quot;red&quot;, lty = 2) Xs = apply(X, 2, scale) G = Xs %*% t(Xs)/ncol(X) Ne = -1/mean(G[col(G) &lt; row(G)]) Me = 1/var(G[col(G) &lt; row(G)]) print(paste(&quot;Ne=&quot;, Ne, &quot;Me=&quot;, Me, &quot;given N=&quot;, nrow(Xs), &quot;and M=&quot;, ncol(Xs))) ## [1] &quot;Ne= 100 Me= 1080.91076380488 given N= 100 and M= 1000&quot; hist(G[col(G) &lt; row(G)], main = &quot;GRM&quot;, xlab = &quot;Relatedness&quot;, breaks = 25) legend(&quot;topright&quot;, legend = c(paste0(&quot;Ne=&quot;, format(Ne, digits = 2)), paste0(&quot;Me=&quot;, format(Me, digits = 2))), bty = &quot;n&quot;) # Eigen eigenG = eigen(G) barplot(eigenG$values, main = &quot;Eigenvalues&quot;) plot(eigenG$vectors[, 1], eigenG$vectors[, 2], xlab = &quot;Eigen 1&quot;, ylab = &quot;Eigen 2&quot;, bty = &quot;n&quot;, main = &quot;Eigenspace&quot;, pch = 16, cex = 0.5, col = ifelse(eigenG$vectors[, 1] &gt; 0, &quot;red&quot;, &quot;blue&quot;)) abline(v = 0, col = &quot;grey&quot;, lty = 2) 1.2.1 \\(\\lambda_{GC}\\) correction We can define \\(\\lambda_{GC}=\\chi^2_{1,median(p)}/\\chi^2_{1,0.5}\\), in which \\(\\chi^2_{1,0.5}=0.455\\). We further use subscript \\(k\\) to denote \\(\\lambda_{GC_k}\\) the one that is estimated from the EigenGWAS analysis of \\(\\mathbf{E}_k\\), as shown (1.5). After technical correction, correspondingly \\[\\begin{equation} \\tilde\\chi^2_1=\\chi^2_1/\\lambda_{GC} \\tag{1.7} \\end{equation}\\] a correction of the test statistic compared to its original form. This correction has several implications Statistically, as (1.5) has its response variable from \\(\\mathbf{X}\\), the correctin removes its overfitting. Genetically, it corrects for genetic drift such as for \\(\\mathbf{E}_1\\). Here quantity of the genetic drift is measured by the median value of the \\(\\chi^2_1\\) values observed. Chi=rchisq(10000, 1, ncp=0.2) layout(matrix(1:2, 1, 2)) qqplot(main=&quot;Raw&quot;, rchisq(1000,1), Chi, bty=&quot;n&quot;, xlab=expression(paste(&quot;Theoretical &quot;,chi[1]^2)), ylab=expression(paste(&quot;Observed &quot;,chi[1]^2)), pch=16, cex=0.5) abline(a=0, b=1, col=&quot;red&quot;, lty=2) gc=median(Chi)/qchisq(0.5, 1, lower.tail = F) ChiGC=Chi/gc qqplot(main=&quot;After correction&quot;, rchisq(1000,1), ChiGC, bty=&quot;n&quot;, xlab=expression(paste(&quot;Theoretical &quot;,chi[1]^2)), ylab=expression(paste(&quot;Observed &quot;,chi[1]^2)), pch=16, cex=0.5) abline(a=0, b=1, col=&quot;red&quot;, lty=2) 1.3 Connection to SVD Singular value decomposition, see SVD wiki for more details, can decompose the matrix \\(\\mathbf{X}\\) into \\[\\begin{equation} \\mathbf{X}=\\mathbf{U\\Sigma V} \\tag{1.8} \\end{equation}\\] in which \\(\\mathbf{U}\\) is an \\(n\\times n\\) unitary matrix, corresponding to individual-level loading for each sample, \\(\\mathbf{\\Sigma}\\) an \\(n\\times m\\) diagonal matrix, and \\(\\mathbf{V}\\) an \\(m\\times m\\) unitary matrix, corresponding to SNP-level loading. Due to the transformation between \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\), it has \\[\\begin{equation} \\mathbf{U}=\\mathbf{\\tilde{X}V\\Sigma}^{-1} \\tag{1.9} \\end{equation}\\] The right side can be unfolded as \\(\\frac{\\sqrt{m}}{\\sqrt{\\Sigma_k}}\\mathbf{x}_l\\mathbf{v}_k\\), follows \\(N(0,1)\\), and taking square of it leads to \\[\\begin{equation} (\\frac{\\sqrt{m}}{\\sqrt{\\Sigma_k}}\\mathbf{\\tilde{x}}_l\\mathbf{v}_k)^2 \\sim \\chi^2_1 \\tag{1.10} \\end{equation}\\] It brings out an interesting comparison between (1.7) and (1.9). The subtle difference, for instance for \\(E_1\\), in their correction using \\(\\lambda_{GC}\\) and \\(\\Sigma_1\\). When the population divergency is due to genetic drift and a small proportion of loci are under selection, \\(\\Sigma_1 \\gt \\lambda_{GC}\\). It is because \\(\\Sigma_1\\) is the mean of the \\(\\chi^2_1\\) from (1.6), but \\(\\lambda_{GC}\\) is the median of it. Given a population under selection, such as selection sweep, it does have \\(\\lambda_{GC} \\gt \\Sigma_1\\), as demonstrated in simulation. So, using linear model system such as EigenGWAS gives more flexibility, as well as improved statistical power comparing with SVD transformation. However, in this transformation, eigenvalue is involved, as would be show. It will reduce the statistical power for EigenGWAS. 1.3.1 Threshold for EigenGWAS As shown above, EigenGWAS is a linear model framework nearly identical to the conventional GWAS, and Bonferroni correction, such as \\(\\alpha/m\\), can be used to set the threshold at the significance level \\(\\alpha\\), such as \\(\\alpha=0.05\\). 1.4 Classic mechanic intepretation The EigenGWAS model resembles the Newtown’s first and the second law for classical mechanics. The first law states that “In an inertial frame of reference, an object either remains at rest or continues to move at a constant velocity, unless acted upon by a force.” Analogously, in population genetics, it can be seemed as genetic drift that is constantly driving the a pair of population apart from each other, and its velocity can be quantified by a binomial distribution as \\(\\frac{pq}{\\tilde{n}_e}\\). “In an inertial frame of reference, the vector sum of the forces \\(F\\) on an object is equal to the mass m of that object multiplied by the acceleration a of the object: \\(F = ma\\).” Analogously, the selection can drive a genomic region run against its reference population at a velocity greater than \\(\\frac{pq}{\\tilde{n}_e}\\). "],
["protocols.html", "Chapter 2 Protocols 2.1 Protocols for selection 2.2 Protocal for EigenGWAS 2.3 Protocol for predicted eigenvectors", " Chapter 2 Protocols 2.1 Protocols for selection Constructing genetic relationship matrix \\(\\mathbf{G}\\). The difference between a random mating population and inbred population is the way \\(\\mathbf{G}\\) is constructed. So for a pair of individuals \\(i\\) and \\(j\\), \\[G_{ij}=\\frac{1}{\\tilde{m}}\\sum_l^{\\tilde{m}}\\frac{(x_{il}-2p_l)(x_{jl}-2p_l)}{2(1+F)p_lq_l}\\] and \\(F=1\\) for inbred lines. Please refer to Chapter 1. Conducting eigenanalysis for \\(\\mathbf{G}\\), see it definition (1.1). Linear regression analysis for each SNP. 2.2 Protocal for EigenGWAS A simple analysis pipeline written in Rscript may be found at my Rpub. 2.3 Protocol for predicted eigenvectors The prediction accuracy can be written as \\[R^2 \\approx \\frac{1}{1+\\frac{n_e}{m}}\\] "],
["resequencing-studies.html", "Chapter 3 Resequencing studies 3.1 Technical review 3.2 Drop HWE test", " Chapter 3 Resequencing studies This is a technical review for resequencing studies. 3.1 Technical review 3.1.1 NGS 3.1.2 Chip data 3.1.3 GBS 3.2 Drop HWE test "],
["simulating-population-structure.html", "Chapter 4 Simulating population structure 4.1 Genetic drift 4.2 Three pop 4.3 Six pop 4.4 Wishart distribution simulation 4.5 Distribution of the Wishart diagonal elements 4.6 Homo cohort 4.7 Heterogeneous cohort 4.8 Tracy-Widom distribution", " Chapter 4 Simulating population structure A toy example for this Charpter can be found in gc5k’s Rpub 4.1 Genetic drift As each locus follows binomial distribution, the genetic drift can be modelled \\(\\frac{\\sqrt{pq}}{2n_e}\\), in which \\(n_e\\) is the effective population size. 4.2 Three pop 4.3 Six pop 4.4 Wishart distribution simulation R function rWishart can generate Wishart distribution easiliy. ## Artificial S &lt;- toeplitz((10:1)/10) set.seed(11) R &lt;- rWishart(1000, 20, S) dim(R) # 10 10 1000 ## [1] 10 10 1000 4.5 Distribution of the Wishart diagonal elements 4.6 Homo cohort 4.7 Heterogeneous cohort 4.8 Tracy-Widom distribution R package RMTstat can help study Tracy-Widom distribution. library(RMTstat) plot(density(rtw(1000)), main=&quot;TW distribbtion&quot;, bty=&#39;n&#39;) "],
["applications.html", "Chapter 5 Applications 5.1 Analysis pipeline 5.2 Examples 5.3 Sea volumn data (NEO)", " Chapter 5 Applications 5.1 Analysis pipeline 5.1.1 Commandline protocol 5.1.2 Web interactive tools 5.2 Examples 5.2.1 Arabdiopsis 5.2.2 ALS 5.2.3 GF 5.2.4 UK birds 5.2.5 Darwin’s finches 5.2.6 Maize (Li HH) 5.2.7 3K rice 5.3 Sea volumn data (NEO) "],
["data-analysis.html", "Chapter 6 Data analysis 6.1 On site examples 6.2 Public datahub (NEO)", " Chapter 6 Data analysis 6.1 On site examples 6.1.1 Arabdiopsis 6.1.2 3K rice 6.1.3 ALS 6.1.4 GF 6.1.5 UK birds 6.1.6 Darwin’s finches 6.1.7 GBS Maize 6.1.8 UK Biobank 6.2 Public datahub (NEO) "],
["meta-research.html", "Chapter 7 Meta-research 7.1 \\(n_e\\) 7.2 \\(m_e\\)", " Chapter 7 Meta-research Meta-research 7.1 \\(n_e\\) 7.2 \\(m_e\\) "],
["conclusion.html", "Chapter 8 Conclusion 8.1 Statistical power 8.2 Selection pattern", " Chapter 8 Conclusion 8.1 Statistical power 8.2 Selection pattern "],
["app-1.html", "Chapter 9 Appendix 1", " Chapter 9 Appendix 1 "],
["references.html", "References", " References "]
]
